{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f6ed181",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ahmadabdullah/Desktop/pipeline/venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import shap\n",
    "\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, RobustScaler\n",
    "import joblib\n",
    "from lightgbm import LGBMClassifier  # If using LightGBM\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01892498",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoanFeatureEngineer:\n",
    "    def __init__(self):\n",
    "        self.edu_map = {\"High School\": 1, \"Bachelor's\": 2, \"Master's\": 3, \"PhD\": 4}\n",
    "        self.medians = None\n",
    "        self.columns = None\n",
    "\n",
    "    def fit(self, df):\n",
    "        DF = self._engineer_features(df.copy())\n",
    "        self.medians = DF.median(numeric_only=True)\n",
    "        self.columns = DF.columns.tolist()\n",
    "        return DF\n",
    "\n",
    "    def transform(self, df):\n",
    "        DF = self._engineer_features(df.copy())\n",
    "        DF = DF.fillna(self.medians)\n",
    "        if self.columns is not None:\n",
    "            DF = DF.reindex(columns=self.columns, fill_value=0)\n",
    "        return DF\n",
    "\n",
    "    def save(self, path):\n",
    "        joblib.dump({'medians': self.medians, 'columns': self.columns}, path)\n",
    "\n",
    "    def load(self, path):\n",
    "        state = joblib.load(path)\n",
    "        self.medians = state['medians']\n",
    "        self.columns = state['columns']\n",
    "\n",
    "    def _engineer_features(self, df):\n",
    "        rng = np.random.default_rng(42)\n",
    "        # ========== NUMERIC DERIVATIVES ==========\n",
    "        df[\"LoanToIncomeRatio\"] = (df[\"LoanAmount\"] / df[\"Income\"]).replace([np.inf, -np.inf], np.nan)\n",
    "        df[\"DebtBurdenIndex\"] = df[\"DTIRatio\"] * df[\"LoanToIncomeRatio\"]\n",
    "        df[\"EffectiveInterestExposure\"] = (df[\"InterestRate\"] * df[\"LoanTerm\"]) / 12\n",
    "        df[\"RiskAdjustedLoan\"] = df[\"LoanAmount\"] * (1 / df[\"CreditScore\"].replace(0, np.nan))\n",
    "        df[\"CreditUtilizationRatio\"] = df[\"LoanAmount\"] / (df[\"NumCreditLines\"] * df[\"Income\"] / 12 + 1e-6)\n",
    "        df[\"EmploymentStabilityScore\"] = np.log1p(df[\"MonthsEmployed\"])\n",
    "        df[\"CreditLinesPerYear\"] = df[\"NumCreditLines\"] / ((df[\"MonthsEmployed\"] / 12) + 1)\n",
    "        df[\"CareerContinuityIndex\"] = (df[\"MonthsEmployed\"] / (df[\"LoanTerm\"] + 1)) * 10\n",
    "        df[\"IncomeStabilityIndex\"] = (1 / (1 + df[\"DTIRatio\"])) * np.log1p(df[\"MonthsEmployed\"])\n",
    "        df[\"FinancialHealthIndex\"] = (\n",
    "            (df[\"CreditScore\"] / 850) * 0.5 +\n",
    "            (1 - df[\"LoanToIncomeRatio\"].clip(0, 2)) * 0.3 +\n",
    "            (1 - df[\"DTIRatio\"].clip(0, 1.5)) * 0.2\n",
    "        )\n",
    "        df[\"BorrowingPressureScore\"] = (\n",
    "            (df[\"InterestRate\"] / 100) * 0.4 +\n",
    "            (df[\"LoanTerm\"] / 60) * 0.3 +\n",
    "            (df[\"DTIRatio\"].clip(0, 2)) * 0.3\n",
    "        )\n",
    "        df[\"CreditMaturityIndex\"] = (df[\"LoanTerm\"] / 12) / (df[\"NumCreditLines\"] + 1)\n",
    "        df[\"IncomeCreditScoreInteraction\"] = df[\"Income\"] * df[\"CreditScore\"]\n",
    "        df[\"LoanTermByInterest\"] = df[\"LoanTerm\"] * df[\"InterestRate\"]\n",
    "        df[\"CombinedDebtIndex\"] = df[\"DTIRatio\"] * df[\"LoanToIncomeRatio\"]\n",
    "\n",
    "        # ========== CATEGORICAL/ORDINAL SIGNALS ==========\n",
    "        if \"Education\" in df.columns and df[\"Education\"].dtype == object:\n",
    "            df[\"EducationLevelIndex\"] = df[\"Education\"].map(self.edu_map).fillna(0).astype(int)\n",
    "        else:\n",
    "            df[\"EducationLevelIndex\"] = 0\n",
    "\n",
    "        def _flag(col, value):\n",
    "            return (df[col] == value).astype(float) if (col in df.columns and df[col].dtype == object) else 0.0\n",
    "        is_full_time = _flag(\"EmploymentType\", \"Full-time\")\n",
    "        is_self_emp  = _flag(\"EmploymentType\", \"Self-employed\")\n",
    "        is_unemp     = _flag(\"EmploymentType\", \"Unemployed\")\n",
    "        is_part_time = _flag(\"EmploymentType\", \"Part-time\")\n",
    "class LoanFeatureEngineer:\n",
    "    def __init__(self):\n",
    "        self.edu_map = {\"High School\": 1, \"Bachelor's\": 2, \"Master's\": 3, \"PhD\": 4}\n",
    "        self.medians = None\n",
    "        self.columns = None\n",
    "\n",
    "    def fit(self, df):\n",
    "        DF = self._engineer_features(df.copy())\n",
    "        self.medians = DF.median(numeric_only=True)\n",
    "        self.columns = DF.columns.tolist()\n",
    "        return DF\n",
    "\n",
    "    def transform(self, df):\n",
    "        DF = self._engineer_features(df.copy())\n",
    "        DF = DF.fillna(self.medians)\n",
    "        if self.columns is not None:\n",
    "            DF = DF.reindex(columns=self.columns, fill_value=0)\n",
    "        return DF\n",
    "\n",
    "    def save(self, path):\n",
    "        joblib.dump({'medians': self.medians, 'columns': self.columns}, path)\n",
    "\n",
    "    def load(self, path):\n",
    "        state = joblib.load(path)\n",
    "        self.medians = state['medians']\n",
    "        self.columns = state['columns']\n",
    "\n",
    "    def _engineer_features(self, df):\n",
    "        rng = np.random.default_rng(42)\n",
    "        # ========== NUMERIC DERIVATIVES ==========\n",
    "        df[\"LoanToIncomeRatio\"] = (df[\"LoanAmount\"] / df[\"Income\"]).replace([np.inf, -np.inf], np.nan)\n",
    "        df[\"DebtBurdenIndex\"] = df[\"DTIRatio\"] * df[\"LoanToIncomeRatio\"]\n",
    "        df[\"EffectiveInterestExposure\"] = (df[\"InterestRate\"] * df[\"LoanTerm\"]) / 12\n",
    "        df[\"RiskAdjustedLoan\"] = df[\"LoanAmount\"] * (1 / df[\"CreditScore\"].replace(0, np.nan))\n",
    "        df[\"CreditUtilizationRatio\"] = df[\"LoanAmount\"] / (df[\"NumCreditLines\"] * df[\"Income\"] / 12 + 1e-6)\n",
    "        df[\"EmploymentStabilityScore\"] = np.log1p(df[\"MonthsEmployed\"])\n",
    "        df[\"CreditLinesPerYear\"] = df[\"NumCreditLines\"] / ((df[\"MonthsEmployed\"] / 12) + 1)\n",
    "        df[\"CareerContinuityIndex\"] = (df[\"MonthsEmployed\"] / (df[\"LoanTerm\"] + 1)) * 10\n",
    "        df[\"IncomeStabilityIndex\"] = (1 / (1 + df[\"DTIRatio\"])) * np.log1p(df[\"MonthsEmployed\"])\n",
    "        df[\"FinancialHealthIndex\"] = (\n",
    "            (df[\"CreditScore\"] / 850) * 0.5 +\n",
    "            (1 - df[\"LoanToIncomeRatio\"].clip(0, 2)) * 0.3 +\n",
    "            (1 - df[\"DTIRatio\"].clip(0, 1.5)) * 0.2\n",
    "        )\n",
    "        df[\"BorrowingPressureScore\"] = (\n",
    "            (df[\"InterestRate\"] / 100) * 0.4 +\n",
    "            (df[\"LoanTerm\"] / 60) * 0.3 +\n",
    "            (df[\"DTIRatio\"].clip(0, 2)) * 0.3\n",
    "        )\n",
    "        df[\"CreditMaturityIndex\"] = (df[\"LoanTerm\"] / 12) / (df[\"NumCreditLines\"] + 1)\n",
    "        df[\"IncomeCreditScoreInteraction\"] = df[\"Income\"] * df[\"CreditScore\"]\n",
    "        df[\"LoanTermByInterest\"] = df[\"LoanTerm\"] * df[\"InterestRate\"]\n",
    "        df[\"CombinedDebtIndex\"] = df[\"DTIRatio\"] * df[\"LoanToIncomeRatio\"]\n",
    "\n",
    "        # ========== CATEGORICAL/ORDINAL SIGNALS ==========\n",
    "        if \"Education\" in df.columns and df[\"Education\"].dtype == object:\n",
    "            df[\"EducationLevelIndex\"] = df[\"Education\"].map(self.edu_map).fillna(0).astype(int)\n",
    "        else:\n",
    "            df[\"EducationLevelIndex\"] = 0\n",
    "\n",
    "        def _flag(col, value):\n",
    "            return (df[col] == value).astype(float) if (col in df.columns and df[col].dtype == object) else 0.0\n",
    "        is_full_time = _flag(\"EmploymentType\", \"Full-time\")\n",
    "        is_self_emp  = _flag(\"EmploymentType\", \"Self-employed\")\n",
    "        is_unemp     = _flag(\"EmploymentType\", \"Unemployed\")\n",
    "        is_part_time = _flag(\"EmploymentType\", \"Part-time\")\n",
    "        is_married   = _flag(\"MaritalStatus\", \"Married\")\n",
    "        df[\"EmploymentStabilityWeight\"] = (\n",
    "            1.0 * is_full_time +\n",
    "            0.7 * is_part_time +\n",
    "            0.6 * is_self_emp +\n",
    "            0.0 * is_unemp\n",
    "        ).replace(0, np.nan).fillna(0.5)\n",
    "\n",
    "        # ========== SYNTHETIC / SEMANTIC FEATURES ==========\n",
    "        # Digital identity & verification\n",
    "        base_dfp = 0.65 + 0.1 * df[\"EducationLevelIndex\"] / 4 + 0.08 * is_full_time + 0.05 * np.log1p(df[\"Income\"]) / np.log(1e6)\n",
    "        df[\"DigitalFootprintScore\"] = np.clip(base_dfp + rng.normal(0, 0.08, len(df)), 0, 1)\n",
    "        # --- Digital identity & verification ---\n",
    "        # Ensure HasMortgage is numeric 0/1 for this computation:\n",
    "        if \"HasMortgage\" in df.columns:\n",
    "            # Map Yes/No or 1/0 to 1/0 (as int)\n",
    "            if df[\"HasMortgage\"].dtype == object:\n",
    "                has_mort = df[\"HasMortgage\"].map({\"Yes\":1,\"No\":0}).fillna(0)\n",
    "            else:\n",
    "                has_mort = df[\"HasMortgage\"].fillna(0).astype(float)\n",
    "        else:\n",
    "            has_mort = 0.0\n",
    "        \n",
    "        lam_pvc = 1.5 + 0.05 * (df[\"Age\"] / 10) + 0.4 * has_mort\n",
    "        # Clip lambda to reasonable range for poisson (avoid too-large/too-small):\n",
    "        lam_pvc = np.clip(lam_pvc, 0.1, 5)\n",
    "        df[\"ProfileVerificationCount\"] = np.clip(rng.poisson(lam=lam_pvc), 0, 5).astype(int)\n",
    "\n",
    "        low = (df[\"Age\"] * 0.3).clip(lower=0)\n",
    "        high = (df[\"Age\"] * 0.8).clip(lower=0)\n",
    "        df[\"IdentityStabilityYears\"] = np.clip(rng.uniform(low, high), 0, None).round(1)\n",
    "        p_multi = np.clip(0.3 + 0.2 * (df[\"EducationLevelIndex\"]/4) + 0.1 * np.log1p(df[\"Income\"])/np.log(1e6), 0, 0.95)\n",
    "        df[\"MultiPlatformPresence\"] = rng.binomial(1, p_multi).astype(int)\n",
    "        # Transactional behavior\n",
    "        mu_opr = 0.7 + 0.1 * (df[\"Income\"] / 100_000) - 0.1 * df[\"DTIRatio\"]\n",
    "        df[\"OnlinePurchaseReliability\"] = np.clip(mu_opr + rng.normal(0, 0.12, len(df)), 0, 1)\n",
    "        mu_upc = 0.6 + 0.2 * (np.log1p(df[\"MonthsEmployed\"])/5) + 0.05 * is_full_time\n",
    "        df[\"UtilityPaymentConsistency\"] = np.clip(mu_upc + rng.normal(0, 0.08, len(df)), 0, 1)\n",
    "        mu_esr = 0.15 + 0.0005 * (35 - df[\"Age\"])\n",
    "        df[\"EcommerceSpendingRatio\"] = np.clip(mu_esr + rng.normal(0, 0.04, len(df)), 0, 0.4)\n",
    "        lam_dsc = 1.5 + 0.5 * (df[\"EducationLevelIndex\"]) + 0.001 * (df[\"Income\"] / 1000)\n",
    "        df[\"DigitalSubscriptionCount\"] = np.clip(rng.poisson(lam=np.clip(lam_dsc, 0.1, 10)), 0, 10).astype(int)\n",
    "        # Social trust & sentiment\n",
    "        mu_sts = 0.5 + 0.05 * (df[\"EducationLevelIndex\"]) + 0.05 * is_full_time\n",
    "        df[\"SocialTrustScore\"] = np.clip(mu_sts + rng.normal(0, 0.12, len(df)), 0, 1)\n",
    "        lam_pcc = 2 - 2 * df[\"SocialTrustScore\"]\n",
    "        df[\"PublicComplaintCount\"] = np.clip(rng.poisson(lam=np.clip(lam_pcc, 0.05, 5)), 0, 5).astype(int)\n",
    "        lam_end = 1 + 0.5 * is_full_time + 0.5 * (df[\"EducationLevelIndex\"])\n",
    "        df[\"EndorsementCount\"] = np.clip(rng.poisson(lam=np.clip(lam_end, 0.05, 10)), 0, 10).astype(int)\n",
    "        df[\"ReviewSentimentIndex\"] = np.clip(df[\"SocialTrustScore\"] + rng.normal(0, 0.1, len(df)), 0, 1)\n",
    "        # Communication & responsiveness\n",
    "        mu_lat = 24 - 12 * df[\"DigitalFootprintScore\"] - 6 * is_full_time\n",
    "        df[\"ResponseLatencyAvgHrs\"] = np.clip(mu_lat + rng.normal(0, 4, len(df)), 1, 48).round(1)\n",
    "        mu_vrr = 0.75 + 0.1 * is_full_time + 0.05 * (df[\"EducationLevelIndex\"]/4)\n",
    "        df[\"VerificationResponseRate\"] = np.clip(mu_vrr + rng.normal(0, 0.08, len(df)), 0, 1)\n",
    "        lam_adc = 1 + 0.002 * (df[\"Income\"] / 1000)\n",
    "        df[\"ActiveDeviceCount\"] = np.clip(rng.poisson(lam=np.clip(lam_adc, 0.1, 6)), 1, 6).astype(int)\n",
    "        # Digital financial literacy\n",
    "        mu_dfl = 0.5 + 0.1 * (df[\"EducationLevelIndex\"]) - 0.003 * df[\"Age\"]\n",
    "        df[\"DigitalFinanceLiteracyScore\"] = np.clip(mu_dfl + rng.normal(0, 0.08, len(df)), 0, 1)\n",
    "        mu_mbu = 0.5 - 0.004 * df[\"Age\"] + 0.1 * (np.log1p(df[\"Income\"]) / np.log(1e6))\n",
    "        df[\"MobileBankingUsageLevel\"] = np.clip(mu_mbu + rng.normal(0, 0.08, len(df)), 0, 1)\n",
    "        lam_fac = 2 + 0.002 * (df[\"Income\"] / 1000) - 0.03 * (df[\"Age\"] - 30)\n",
    "        df[\"FinancialAppCount\"] = np.clip(rng.poisson(lam=np.clip(lam_fac, 0.1, 10)), 0, 10).astype(int)\n",
    "        # Public records & legal standing\n",
    "        lam_prd = 2 - 1.5 * df[\"DigitalFootprintScore\"]\n",
    "        df[\"PublicRecordDiscrepancyCount\"] = np.clip(rng.poisson(lam=np.clip(lam_prd, 0.05, 4)), 0, 4).astype(int)\n",
    "        lam_lic = 3 - 2 * df[\"SocialTrustScore\"]\n",
    "        df[\"LegalInquiryCount\"] = np.clip(rng.poisson(lam=np.clip(lam_lic, 0.05, 5)), 0, 5).astype(int)\n",
    "        df[\"AddressVerificationLevel\"] = np.clip(df[\"DigitalFootprintScore\"] + rng.normal(0, 0.08, len(df)), 0, 1)\n",
    "        # Civic engagement\n",
    "        mu_cei = 0.3 + 0.1 * (df[\"EducationLevelIndex\"]) + 0.0005 * (df[\"Age\"] + df[\"Income\"] / 10_000)\n",
    "        df[\"CivicEngagementIndex\"] = np.clip(mu_cei + rng.normal(0, 0.08, len(df)), 0, 1)\n",
    "        p_vr = np.clip(0.5 + 0.01 * (df[\"Age\"] - 25), 0.0, 0.95)\n",
    "        df[\"VoterRegistrationStatus\"] = rng.binomial(1, p_vr).astype(int)\n",
    "        lam_cac = 1 + 0.5 * is_married\n",
    "        df[\"CommunityAffiliationCount\"] = np.clip(rng.poisson(lam=np.clip(lam_cac, 0.1, 6)), 0, 6).astype(int)\n",
    "        # Professional & occupational signals\n",
    "        mu_pes = 0.5 + 0.2 * is_full_time + 0.1 * is_self_emp\n",
    "        df[\"ProfessionalEndorsementScore\"] = np.clip(mu_pes + rng.normal(0, 0.08, len(df)), 0, 1)\n",
    "        mu_jcf = 3 - np.log1p(df[\"MonthsEmployed\"]) / 2\n",
    "        df[\"JobChangeFrequency5Y\"] = np.clip(mu_jcf + rng.normal(0, 0.5, len(df)), 0, 5)\n",
    "        mu_pwps = 0.4 + 0.2 * is_self_emp + 0.1 * (df[\"EducationLevelIndex\"])\n",
    "        df[\"PublicWorkPortfolioScore\"] = np.clip(mu_pwps + rng.normal(0, 0.12, len(df)), 0, 1)\n",
    "        # Aggregated composites\n",
    "        df[\"DigitalTrustComposite\"] = df[[\"DigitalFootprintScore\", \"SocialTrustScore\", \"AddressVerificationLevel\"]].mean(axis=1)\n",
    "        df[\"CivicResponsibilityIndex\"] = df[[\"CivicEngagementIndex\", \"VoterRegistrationStatus\"]].mean(axis=1)\n",
    "        df[\"OnlineBehaviorIndex\"] = df[[\"OnlinePurchaseReliability\", \"UtilityPaymentConsistency\", \"MobileBankingUsageLevel\"]].mean(axis=1)\n",
    "        # Cleanup\n",
    "        df = df.replace([np.inf, -np.inf], np.nan)\n",
    "        return df\n",
    "\n",
    "class LoanPreprocessor:\n",
    "    def __init__(self):\n",
    "        self.cat_cols = None\n",
    "        self.num_cols = None\n",
    "        self.target_col = None\n",
    "        self.label_encoders = {}\n",
    "        self.scaler = None\n",
    "\n",
    "    def fit_transform(self, df):\n",
    "        dfp = df.copy()\n",
    "        # Drop identifier columns\n",
    "        dfp.drop(columns=[\"LoanID\"], inplace=True, errors=\"ignore\")\n",
    "        # 1. Normalize binary flags\n",
    "        for col in [\"HasMortgage\", \"HasDependents\", \"HasCoSigner\"]:\n",
    "            if col in dfp.columns:\n",
    "                if dfp[col].dtype == object:\n",
    "                    dfp[col] = dfp[col].str.strip().map({\"Yes\": 1, \"No\": 0})\n",
    "                dfp[col] = dfp[col].fillna(0).astype(\"int8\")\n",
    "        # 2. Identify column groups\n",
    "        self.cat_cols = [c for c in [\"Education\", \"EmploymentType\", \"MaritalStatus\", \"LoanPurpose\"] if c in dfp.columns]\n",
    "        self.target_col = \"Default\" if \"Default\" in dfp.columns else None\n",
    "        self.num_cols = [c for c in dfp.columns if c not in self.cat_cols + [self.target_col] and pd.api.types.is_numeric_dtype(dfp[c])]\n",
    "        # 3. Handle missing values\n",
    "        for c in self.num_cols:\n",
    "            dfp[c] = dfp[c].replace([np.inf, -np.inf], np.nan)\n",
    "            dfp[c] = dfp[c].astype(\"float64\")\n",
    "            dfp[c] = dfp[c].fillna(dfp[c].median())\n",
    "        for c in self.cat_cols:\n",
    "            dfp[c] = dfp[c].astype(str).str.strip().replace({\"\": \"Unknown\", \"nan\": \"Unknown\"}).fillna(\"Unknown\")\n",
    "        if self.target_col:\n",
    "            dfp[self.target_col] = dfp[self.target_col].astype(\"int8\")\n",
    "        # 4. Label encoding for categoricals\n",
    "        self.label_encoders = {}\n",
    "        for c in self.cat_cols:\n",
    "            le = LabelEncoder()\n",
    "            dfp[c] = le.fit_transform(dfp[c].astype(str))\n",
    "            self.label_encoders[c] = le\n",
    "        # 5. Downcast numerics\n",
    "        for c in self.num_cols:\n",
    "            if pd.api.types.is_float_dtype(dfp[c]):\n",
    "                dfp[c] = pd.to_numeric(dfp[c], downcast=\"float\")\n",
    "            elif pd.api.types.is_integer_dtype(dfp[c]):\n",
    "                dfp[c] = pd.to_numeric(dfp[c], downcast=\"integer\")\n",
    "        # 6. Apply RobustScaler on numeric features\n",
    "        self.scaler = RobustScaler()\n",
    "        dfp[self.num_cols] = self.scaler.fit_transform(dfp[self.num_cols])\n",
    "        # 7. Final cleanup\n",
    "        dfp = dfp.replace([np.inf, -np.inf], np.nan)\n",
    "        for c in self.num_cols:\n",
    "            dfp[c] = dfp[c].fillna(dfp[c].median())\n",
    "        # 8. Return as DF (final, ready-to-use DataFrame)\n",
    "        global DF\n",
    "        DF = dfp\n",
    "        return DF\n",
    "\n",
    "    def transform(self, df):\n",
    "        dfp = df.copy()\n",
    "        dfp.drop(columns=[\"LoanID\"], inplace=True, errors=\"ignore\")\n",
    "        # 1. Normalize binary flags\n",
    "        for col in [\"HasMortgage\", \"HasDependents\", \"HasCoSigner\"]:\n",
    "            if col in dfp.columns:\n",
    "                if dfp[col].dtype == object:\n",
    "                    dfp[col] = dfp[col].str.strip().map({\"Yes\": 1, \"No\": 0})\n",
    "                dfp[col] = dfp[col].fillna(0).astype(\"int8\")\n",
    "        # 2. Handle missing values for numerics/cats (use previously set cols)\n",
    "        for c in self.num_cols:\n",
    "            dfp[c] = dfp[c].replace([np.inf, -np.inf], np.nan)\n",
    "            dfp[c] = dfp[c].astype(\"float64\")\n",
    "            dfp[c] = dfp[c].fillna(dfp[c].median())\n",
    "        for c in self.cat_cols:\n",
    "            dfp[c] = dfp[c].astype(str).str.strip().replace({\"\": \"Unknown\", \"nan\": \"Unknown\"}).fillna(\"Unknown\")\n",
    "        if self.target_col and self.target_col in dfp.columns:\n",
    "            dfp[self.target_col] = dfp[self.target_col].astype(\"int8\")\n",
    "        # 3. Label encoding (use fitted encoders, handle unseen as 'Unknown')\n",
    "        for c in self.cat_cols:\n",
    "            le = self.label_encoders[c]\n",
    "            vals = dfp[c].astype(str)\n",
    "            unseen = ~vals.isin(le.classes_)\n",
    "            if unseen.any():\n",
    "                vals[unseen] = \"Unknown\"\n",
    "                le_classes = np.append(le.classes_, \"Unknown\")\n",
    "                le.classes_ = le_classes\n",
    "            dfp[c] = le.transform(vals)\n",
    "        # 4. Downcast numerics\n",
    "        for c in self.num_cols:\n",
    "            if pd.api.types.is_float_dtype(dfp[c]):\n",
    "                dfp[c] = pd.to_numeric(dfp[c], downcast=\"float\")\n",
    "            elif pd.api.types.is_integer_dtype(dfp[c]):\n",
    "                dfp[c] = pd.to_numeric(dfp[c], downcast=\"integer\")\n",
    "        # 5. Scale numerics\n",
    "        dfp[self.num_cols] = self.scaler.transform(dfp[self.num_cols])\n",
    "        # 6. Final cleanup\n",
    "        dfp = dfp.replace([np.inf, -np.inf], np.nan)\n",
    "        for c in self.num_cols:\n",
    "            dfp[c] = dfp[c].fillna(dfp[c].median())\n",
    "        global DF\n",
    "        DF = dfp\n",
    "        return DF\n",
    "\n",
    "    def save(self, path):\n",
    "        state = {\n",
    "            \"cat_cols\": self.cat_cols,\n",
    "            \"num_cols\": self.num_cols,\n",
    "            \"target_col\": self.target_col,\n",
    "            \"label_encoders\": self.label_encoders,\n",
    "            \"scaler\": self.scaler\n",
    "        }\n",
    "        joblib.dump(state, path)\n",
    "\n",
    "    def load(self, path):\n",
    "        state = joblib.load(path)\n",
    "        self.cat_cols = state[\"cat_cols\"]\n",
    "        self.num_cols = state[\"num_cols\"]\n",
    "        self.target_col = state[\"target_col\"]\n",
    "        self.label_encoders = state[\"label_encoders\"]\n",
    "        self.scaler = state[\"scaler\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b3beab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ahmadabdullah/Desktop/pipeline/venv/lib/python3.13/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.5.2 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/ahmadabdullah/Desktop/pipeline/venv/lib/python3.13/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator RobustScaler from version 1.5.2 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:8000\n",
      " * Running on http://10.112.128.154:8000\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "INFO:werkzeug: * Restarting with stat\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/ahmadabdullah/Desktop/pipeline/venv/lib/python3.13/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/Users/ahmadabdullah/Desktop/pipeline/venv/lib/python3.13/site-packages/traitlets/config/application.py\", line 1074, in launch_instance\n",
      "    app.initialize(argv)\n",
      "    ~~~~~~~~~~~~~~^^^^^^\n",
      "  File \"/Users/ahmadabdullah/Desktop/pipeline/venv/lib/python3.13/site-packages/traitlets/config/application.py\", line 118, in inner\n",
      "    return method(app, *args, **kwargs)\n",
      "  File \"/Users/ahmadabdullah/Desktop/pipeline/venv/lib/python3.13/site-packages/ipykernel/kernelapp.py\", line 711, in initialize\n",
      "    self.init_sockets()\n",
      "    ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/Users/ahmadabdullah/Desktop/pipeline/venv/lib/python3.13/site-packages/ipykernel/kernelapp.py\", line 333, in init_sockets\n",
      "    self.shell_port = self._bind_socket(self.shell_socket, self.shell_port)\n",
      "                      ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ahmadabdullah/Desktop/pipeline/venv/lib/python3.13/site-packages/ipykernel/kernelapp.py\", line 255, in _bind_socket\n",
      "    return self._try_bind_socket(s, port)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^\n",
      "  File \"/Users/ahmadabdullah/Desktop/pipeline/venv/lib/python3.13/site-packages/ipykernel/kernelapp.py\", line 231, in _try_bind_socket\n",
      "    s.bind(\"tcp://%s:%i\" % (self.ip, port))\n",
      "    ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ahmadabdullah/Desktop/pipeline/venv/lib/python3.13/site-packages/zmq/sugar/socket.py\", line 320, in bind\n",
      "    super().bind(addr)\n",
      "    ~~~~~~~~~~~~^^^^^^\n",
      "  File \"zmq/backend/cython/_zmq.py\", line 1009, in zmq.backend.cython._zmq.Socket.bind\n",
      "    _check_rc(rc)\n",
      "    \n",
      "  File \"zmq/backend/cython/_zmq.py\", line 190, in zmq.backend.cython._zmq._check_rc\n",
      "    raise ZMQError(errno)\n",
      "    \n",
      "zmq.error.ZMQError: Address already in use (addr='tcp://127.0.0.1:9018')\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ahmadabdullah/Desktop/pipeline/venv/lib/python3.13/site-packages/IPython/core/interactiveshell.py:3707: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# ========== LOAD ARTIFACTS AND MODEL ==========\n",
    "ARTIFACTS_DIR = Path('artifacts')\n",
    "MODELS_DIR = Path('models')\n",
    "LGBM_MODEL_PATH = MODELS_DIR / \"LGBM_model.pkl\"\n",
    "FEATURE_ENG_PATH = ARTIFACTS_DIR / \"feature_engineering_artifacts.pkl\"\n",
    "PREPROCESS_PATH = ARTIFACTS_DIR / \"preprocessing_artifacts.pkl\"\n",
    "\n",
    "feature_engineer = LoanFeatureEngineer()\n",
    "feature_engineer.load(FEATURE_ENG_PATH)\n",
    "preprocessor = LoanPreprocessor()\n",
    "preprocessor.load(PREPROCESS_PATH)\n",
    "model = joblib.load(LGBM_MODEL_PATH)\n",
    "explainer = shap.TreeExplainer(model)\n",
    "\n",
    "# ========== FLASK SETUP ==========\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(\"backend\")\n",
    "\n",
    "@app.route(\"/health\", methods=[\"GET\"])\n",
    "def health() -> object:\n",
    "    return jsonify({\"status\": \"ok\"})\n",
    "\n",
    "@app.route(\"/predict\", methods=[\"POST\"])\n",
    "def predict() -> object:\n",
    "    try:\n",
    "        form_data = request.get_json(force=True)\n",
    "        logger.info(\"/predict called - received request body\")\n",
    "        logger.debug(\"request.json=%s\", json.dumps(form_data, separators=(\",\", \":\"))[:400])\n",
    "    except Exception:\n",
    "        logger.exception(\"Invalid JSON body\")\n",
    "        return jsonify({\"error\": \"Invalid JSON body\"}), 400\n",
    "\n",
    "    try:\n",
    "        prediction = predict_lgbm(form_data)\n",
    "        logger.info(\"Model output: %s\", json.dumps(prediction, separators=(\",\", \":\"))[:400])\n",
    "        verdict_text = generate_verdict_with_gpt(prediction, form_data)\n",
    "        prediction[\"verdict\"] = verdict_text\n",
    "        logger.info(\"/predict completed successfully\")\n",
    "        return jsonify(prediction)\n",
    "    except Exception:\n",
    "        logger.exception(\"Prediction failed\")\n",
    "        return jsonify({\"error\": \"Internal error during prediction\"}), 500\n",
    "\n",
    "def predict_lgbm(form_data):\n",
    "    if isinstance(form_data, dict):\n",
    "        df_input = pd.DataFrame([form_data])\n",
    "    else:\n",
    "        df_input = pd.DataFrame(form_data)\n",
    "    # 1. Feature engineering\n",
    "    df_feat = feature_engineer.transform(df_input)\n",
    "    # 2. Preprocessing (scaling, label encoding)\n",
    "    df_ready = preprocessor.transform(df_feat)\n",
    "    if \"Default\" in df_ready.columns:\n",
    "        df_ready = df_ready.drop(columns=[\"Default\"])\n",
    "    # 3. Prediction and SHAP\n",
    "    prob = float(model.predict_proba(df_ready)[:, 1][0])\n",
    "    pred = int(model.predict(df_ready)[0])\n",
    "    shap_values = explainer.shap_values(df_ready)\n",
    "    shap_vals = shap_values[1][0] if isinstance(shap_values, list) else shap_values[0]\n",
    "    feature_names = df_ready.columns.tolist()\n",
    "    contrib = dict(zip(feature_names, shap_vals))\n",
    "    abs_importance = dict(zip(feature_names, np.abs(shap_vals)))\n",
    "    contrib_sorted = {k: v for k, v in sorted(contrib.items(), key=lambda item: -abs(item[1]))}\n",
    "    abs_importance_sorted = {k: v for k, v in sorted(abs_importance.items(), key=lambda item: -item[1])}\n",
    "    return {\n",
    "        \"prediction\": pred,\n",
    "        \"probability\": prob,\n",
    "        \"shap_contribution\": contrib_sorted,\n",
    "        \"shap_importance\": abs_importance_sorted\n",
    "    }\n",
    "\n",
    "def generate_verdict_with_gpt(prediction, form_data):\n",
    "    api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "    default_probability = float(prediction.get(\"probability\", 0.0))\n",
    "    risk_level = \"HIGH\" if default_probability > 0.7 else (\"MEDIUM\" if default_probability > 0.4 else \"LOW\")\n",
    "    top_factors = \", \".join(list(prediction[\"shap_importance\"].keys())[:3])\n",
    "    shap_json = json.dumps({k: float(v) for k, v in list(prediction['shap_contribution'].items())[:5]}, separators=(\",\", \":\"))\n",
    "    prompt = (\n",
    "        f\"You are a senior credit risk analyst. Given the model output below, explain to a loan officer in plain English.\\n\"\n",
    "        f\"Default probability: {default_probability * 100:.1f}%\\n\"\n",
    "        f\"Risk level: {risk_level}\\n\"\n",
    "        f\"Top factors: {top_factors}\\n\"\n",
    "        f\"Applicant: {json.dumps(form_data)[:400]}\\n\"\n",
    "        f\"SHAP contributions: {shap_json}\\n\"\n",
    "        \"Recommend whether to approve or decline, with reasons.\"\n",
    "    )\n",
    "    if not api_key:\n",
    "        fallback = {\n",
    "            \"HIGH\": f\"High default risk ({default_probability:.2%}). Main concerns: {top_factors}. Recommend decline or stricter terms.\",\n",
    "            \"MEDIUM\": f\"Moderate default risk ({default_probability:.2%}). Monitor key factors: {top_factors}. Consider standard or slightly stricter terms.\",\n",
    "            \"LOW\": f\"Low default risk ({default_probability:.2%}). Strong applicant due to {top_factors}. Recommend approval.\",\n",
    "        }\n",
    "        return fallback[risk_level]\n",
    "    try:\n",
    "        from openai import OpenAI\n",
    "        client = OpenAI(api_key=api_key)\n",
    "        model_name = os.environ.get(\"OPENAI_MODEL\", \"gpt-4o-mini\")\n",
    "        response = client.chat.completions.create(\n",
    "            model=model_name,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert credit risk assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.3,\n",
    "            max_tokens=160,\n",
    "        )\n",
    "        content = (response.choices[0].message.content or \"\").strip()\n",
    "        return content\n",
    "    except Exception:\n",
    "        logger.exception(\"OpenAI API call failed, using fallback verdict.\")\n",
    "        fallback = {\n",
    "            \"HIGH\": f\"High default risk ({default_probability:.2%}). Main concerns: {top_factors}. Recommend decline or stricter terms.\",\n",
    "            \"MEDIUM\": f\"Moderate default risk ({default_probability:.2%}). Monitor key factors: {top_factors}. Consider standard or slightly stricter terms.\",\n",
    "            \"LOW\": f\"Low default risk ({default_probability:.2%}). Strong applicant due to {top_factors}. Recommend approval.\",\n",
    "        }\n",
    "        return fallback[risk_level]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host=\"0.0.0.0\", port=int(os.environ.get(\"PORT\", 8000)), debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fef432",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
